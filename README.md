# Mini-Llama-3

------

This is a example implementation of the Llama-3 architecture. 

Here are a few details:

-Model dimensions: **128**

-Model Layers: **8**

- Model Heads: **8**

-----

### Usage

```python
python train.py
```





